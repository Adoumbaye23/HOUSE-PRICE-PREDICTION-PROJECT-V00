











import pandas as pd
import numpy as np
from scipy import stats
from sklearn import metrics
import joblib

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.compose import make_column_transformer, ColumnTransformer
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder

from sklearn.linear_model import LinearRegression, Ridge, Lasso,ElasticNet
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor
from xgboost import XGBRegressor
from catboost import CatBoostRegressor
import lightgbm as LGBMRegressor
from yellowbrick.regressor import ResidualsPlot
import missingno as msno
import pickle
from plotly.subplots import make_subplots
import plotly.graph_objects as go


data= pd.read_csv("../data/data_apuree.csv")
data.head(3)






def get_all_performances(value_train: tuple,
                         values_test: tuple,
                         metrics: list,
                        ) -> pd.DataFrame:
    """ Get all performance metrics listed in `metrics`

    Args:
        value_train (tuple): (y_train, y_train_pred)
        values_test (tuple): (y_test, y_test_pred)
        metrics (list): list of metrics to compute


    Returns:
        pd.DataFrame: column names are: ["metric", "train", "test"]

    """
    test_perfs = []
    train_perfs = []
    metric_names = []
    for metric_func in metrics:
        metric_name = metric_func.__name__
        metric_names.append(metric_name)
        train_perfs.append(metric_func(*value_train))
        test_perfs.append(metric_func(*values_test))
    perfs = {"metric": metric_names, "train": train_perfs, "test": test_perfs,}
    return pd.DataFrame(perfs)


METRICS = [metrics.r2_score,
           metrics.root_mean_squared_error,
           metrics.mean_absolute_percentage_error,
           metrics.max_error,
          ]


def get_input_features(model_pipeline, cat_step_name=None, ode_step_name=None):
    """
    Récupérer les noms des caractéristiques après transformation dans un pipeline.

    Parameters:
    - model_pipeline : pipeline complet du modèle avec un ColumnTransformer.
    - cat_step_name : nom de l'étape de prétraitement pour les variables catégorielles (optionnel).
    - ode_step_name : nom de l'étape de prétraitement pour les variables ordinales (optionnel).

    Returns:
    - Liste des noms de toutes les caractéristiques après transformation.
    """
    # Accéder au préprocesseur (ColumnTransformer) dans le pipeline
    col_trans = model_pipeline.named_steps['preprocessing']

    all_feature_names = []

    # Boucle sur chaque transformer dans le ColumnTransformer
    for step_name, pipe_trans, feat_names in col_trans.transformers_:
        if step_name == cat_step_name:
            # Récupérer les noms des caractéristiques après l'encodage OneHotEncoder
            if 'ohe' in pipe_trans.named_steps:  # Vérifie si le pipeline a un OneHotEncoder
                cat_feature_names = pipe_trans.named_steps['ohe'].get_feature_names_out(input_features=feat_names)
                all_feature_names.extend(cat_feature_names)
        elif step_name == ode_step_name:
            # Récupérer les noms des caractéristiques après l'encodage OrdinalEncoder
            if 'ode' in pipe_trans.named_steps:  # Vérifie si le pipeline a un OrdinalEncoder
                ode_feature_names = pipe_trans.named_steps['ode'].categories_[0]  # Cela renvoie les catégories de l'OrdinalEncoder
                all_feature_names.extend(ode_feature_names)
        else:
            # Ajouter les noms des caractéristiques pour les autres étapes (numériques)
            all_feature_names.extend(feat_names)

    # Retourner tous les noms des caractéristiques
    return all_feature_names





# Importation
data = pd.read_csv('../data/data_apuree.csv')


data.shape
data


data.describe()


 data.info()


variables_qualitatives = data.select_dtypes(include=['object', 'category']).columns
variables_qualitatives
# Identification des colonnes numériques
numeric_cols = data.select_dtypes(include=['number']).columns.tolist()
numeric_cols.remove('Prix de vente')
print(numeric_cols, variables_qualitatives)





#  soit votre DataFrame et 'SalePrice' la variable cible
X = data.drop(columns=['Prix de vente'])

y = data['Prix de vente']



X_encode = pd.get_dummies(data=X,
                          columns=variables_qualitatives,
                          drop_first=True,
                         )
X_encode.shape





# Colonnes à encoder ordinalement
ode_cols =['LotShape','LandSlope',
    'OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtQual',
    'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC'

]
ode_cols=[
    'Façade (en pieds)', 'Superficie du lot (pieds²)', 'Année de construction',
    'Année de rénovation', 'Surface de parement (pieds²)', 'Surface finie sous-sol',
    'Surface finie sous-sol 2', 'Surface non finie sous-sol', 'Total surface sous-sol',
    'Surface du premier étage', 'Surface du deuxième étage',
    'Surface finie basse qualité (pieds²)', 'Surface habitable totale',
    'Salles de bain complètes sous-sol', 'Demi-salles de bain sous-sol',
    'Salles de bain complètes', 'Demi-salles de bain'
]

# Colonnes à encoder en one-hot
ohe_cols =[
    'MSSubClass', 'MSZoning', 'Street',  'LandContour', 'Utilities',
    'LotConfig',  'Neighborhood', 'Condition1', 'Condition2',
    'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',
    'Exterior2nd', 'Foundation', 'Heating', 'CentralAir','Electrical'
]

ohe_cols=[
    'Type de logement', 'Zonage (Classification)', 'Type de route', 'Forme du lot',
    'Topographie du terrain', 'Services publics disponibles', 'Configuration du lot',
    'Inclinaison du terrain', 'Quartier', 'Proximité (1ère condition)',
    'Proximité (2e condition)', 'Type de bâtiment', 'Style de maison',
    'Qualité globale', 'État général', 'Style de toit', 'Matériau du toit',
    'Revêtement extérieur (1)', 'Revêtement extérieur (2)', 'Qualité extérieure',
    'État extérieur', 'Type de fondation', 'Qualité du sous-sol',
    'État général du sous-sol', 'Exposition du sous-sol',
    'Type de finition sous-sol (1)', 'Type de finition sous-sol (2)',
    'Type de chauffage', 'Qualité du chauffage', 'Climatisation centrale',
    'Système électrique'
]








# Pipeline pour les variables numériques
numeric_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputation des valeurs manquantes
    ('scaler', StandardScaler())  # Normalisation
])
ordinal_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputation des valeurs manquantes
    ('ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))  # Encodage ordinal, handle unknown categories
])


# Pipeline pour les variables avec encodage one-hot
onehot_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputation des valeurs manquantes
    ('onehot_encoder', OneHotEncoder(drop='first',handle_unknown='ignore', sparse_output=False))  # Encodage one-hot
])



preprocessor = ColumnTransformer(transformers=[
    ('num', numeric_pipeline, numeric_cols),
    ('ord', ordinal_pipeline, ode_cols),
    ('ohe', onehot_pipeline, ohe_cols)
])



pipeline = Pipeline(steps=[
    ('preprocessing', preprocessor)
])
pipeline


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12)
print("Entrainement: {} lignes,\nTest: {} lignes.\n".format(X_train.shape[0],
                                                            X_test.shape[0]))





lr_pipe = Pipeline(
    steps=[
        ("preprocessor", preprocessor),
        ("imputer", SimpleImputer(strategy='most_frequent')),
        ("regressor", LinearRegression())
    ]
)


# definir les hyperparametres
param_grid_lr = {
    "regressor__fit_intercept": [True, False],
}

GS_lr = GridSearchCV(lr_pipe, param_grid_lr, cv=10, scoring="r2", return_train_score=True)
GS_lr


# Exécuter la recherche sur la grille
GS_lr.fit(X_train, y_train)
# meilleur combinaison
best_params = GS_lr.best_params_
print(f"Best params: {best_params}")



grid_cv_results = GS_lr.cv_results_
pd.DataFrame(grid_cv_results)


# predictions
y_test_pred_lr = GS_lr.predict(X_test)
y_train_pred_lr = GS_lr.predict(X_train)


## Comparaison réelle et prédiction (train et test)
fig = make_subplots(rows=1, cols=2, shared_yaxes=False)

datasets = [("Train", y_train, y_train_pred_lr), ("Test", y_test, y_test_pred_lr)]

for idx, (name, y_true, y_pred) in enumerate(datasets):
    col = idx + 1
    fig.add_trace(go.Scatter(x=y_true, y=y_pred, mode="markers", name=name), row=1, col=col)

    fig.add_trace(go.Scatter(x=[y_true.min(), y_true.max()],
                             y=[y_true.min(), y_true.max()],
                             mode="lines", name="Diagonal", line=dict(color="black", dash="dash")),
                  row=1, col=col)

fig.update_layout(title_text="Comparaison réelle et prédiction (train et test)", showlegend=True)
fig.show()






# Visualisation des résidus
from yellowbrick.regressor import ResidualsPlot

res_viz = ResidualsPlot(lr_pipe,
                        is_fitted="auto",
                        qqplot=True,
                        hist=False,
                        train_color="blue",
                        test_color="red"
                       )
res_viz.fit(X_train, y_train)
res_viz.score(X_test, y_test)
res_viz.show(clear_figure=True)



# get performances in train & test
perform=get_all_performances(value_train=(y_train, GS_lr.predict(X_train)),
                     values_test=(y_test, GS_lr.predict(X_test)),
                     metrics=METRICS
                    )
perform
joblib.dump(perform, '../ressource/performance/GS_lr_perform.pkl')





EN_pipe = Pipeline(
    steps=[("preprocessor", preprocessor), ("regressor", ElasticNet())]
)
EN_pipe


EN_pipe.fit(X_train, y_train)


# predictions
y_test_pred_EN = EN_pipe.predict(X_test)
y_train_pred_EN = EN_pipe.predict(X_train)


# get performances in train & test
perform=get_all_performances(value_train=(y_train, y_train_pred_EN),
                     values_test=(y_test, y_test_pred_EN),
                     metrics=METRICS)
perform





# optimisation des hyperparamètres
param_grid_EN = {
    "regressor__alpha": [0.005, 0.01, 0.2, 0.3, 0.5, 0.7],
    "regressor__l1_ratio" : [0.001, 0.01, 0.5, 0.3, 0.7, 0.8],
    "regressor__fit_intercept" : [True, False]
}

GS_EN = GridSearchCV(EN_pipe, param_grid_EN, cv=5, scoring="r2", return_train_score=True)


# les meilleurs paramètres
GS_EN.fit(X_train, y_train)

best_params = GS_EN.best_params_
print(f"Best params: {best_params}")


# entrainement du meilleur modele
best_elasticnet_model = GS_EN.best_estimator_
best_elasticnet_model.fit(X_train,y_train)


# get performances in train & test
perform=get_all_performances(value_train=(y_train, best_elasticnet_model.predict(X_train)),
                     values_test=(y_test, best_elasticnet_model.predict(X_test)),
                     metrics=METRICS
                    )
perform
joblib.dump(perform, '../ressource/performance/ElasticNet_perform.pkl')





# future importance
#df_feature_importance = pd.DataFrame(best_elasticnet_model['regressor'].coef_, columns=["coef"], index=X_encode.columns)
#print(f"Shape: {df_feature_importance.shape}")
#df_feature_importance.head()


# future importance
# Get the feature names after the preprocessing step
#feature_names_after_preprocessing = get_input_features(best_elasticnet_model, cat_step_name='ohe_cols', ode_step_name='ord_cols')

# Create the DataFrame using the correct feature names
#df_feature_importance = pd.DataFrame(
#    best_elasticnet_model['regressor'].coef_,
#    columns=["coef"],
#    index=feature_names_after_preprocessing  # Use the transformed feature names
#)
#print(f"Shape: {df_feature_importance.shape}")
#df_feature_importance.head()



def get_input_features(model_pipeline, cat_step_name=None, ode_step_name=None):
    """
    Récupérer les noms des caractéristiques après transformation dans un pipeline.

    Parameters:
    - model_pipeline : pipeline complet du modèle avec un ColumnTransformer.
    - cat_step_name : nom de l'étape de prétraitement pour les variables catégorielles (optionnel).
    - ode_step_name : nom de l'étape de prétraitement pour les variables ordinales (optionnel).

    Returns:
    - Liste des noms de toutes les caractéristiques après transformation.
    """
    # Accéder au préprocesseur (ColumnTransformer) dans le pipeline
    # The step is named 'preprocessor', not 'preprocessing'
    col_trans = model_pipeline.named_steps['preprocessor']

    all_feature_names = []

    # Boucle sur chaque transformer dans le ColumnTransformer
    for step_name, pipe_trans, feat_names in col_trans.transformers_:
        if step_name == cat_step_name:
            # Récupérer les noms des caractéristiques après l'encodage OneHotEncoder
            if 'ohe' in pipe_trans.named_steps:  # Vérifie si le pipeline a un OneHotEncoder
                cat_feature_names = pipe_trans.named_steps['ohe'].get_feature_names_out(input_features=feat_names)
                all_feature_names.extend(cat_feature_names)
        elif step_name == ode_step_name:
            # Récupérer les noms des caractéristiques après l'encodage OrdinalEncoder
            if 'ode' in pipe_trans.named_steps:  # Vérifie si le pipeline a un OrdinalEncoder
                ode_feature_names = pipe_trans.named_steps['ode'].categories_[0]  # Cela renvoie les catégories de l'OrdinalEncoder
                all_feature_names.extend(ode_feature_names)
        else:
            # Ajouter les noms des caractéristiques pour les autres étapes (numériques)
            all_feature_names.extend(feat_names)

    # Retourner tous les noms des caractéristiques
    return all_feature_names





randf_pipe = Pipeline(
    steps=[("preprocessor", preprocessor), ("regressor", RandomForestRegressor())]
)
randf_pipe


# Premier entrainement
randf_pipe.fit(X_train, y_train)


# get performances in train & test
perform=get_all_performances(value_train=(y_train, randf_pipe.predict(X_train)),
                     values_test=(y_test, randf_pipe.predict(X_test)),
                     metrics=METRICS)
perform





# optimisation des hyperparamètres
param_grid_rf = {
    'regressor__n_estimators': [700, 600],
     'regressor__min_samples_split': [5],
    'regressor__max_depth': [None],
    'regressor__min_samples_leaf': [2],
    #'regressor__max_features': ['auto'],#'sqrt'
    'regressor__bootstrap': [True], # False
}

GS_rf = GridSearchCV(randf_pipe, param_grid_rf, cv=5, scoring="r2", return_train_score=True)
GS_rf


# les meilleurs paramètres
GS_rf.fit(X_train, y_train)


# les meilleurs paramètres
best_params = GS_rf.best_params_
print(f"Best params: {best_params}")


# entrainement du meilleur modele
best_randf_model = GS_rf.best_estimator_
best_randf_model.fit(X_train,y_train)





# get performances in train & test
perform=get_all_performances(value_train=(y_train, best_randf_model.predict(X_train)),
                     values_test=(y_test, best_randf_model.predict(X_test)),
                     metrics=METRICS
                    )
perform
joblib.dump(perform, '../ressource/performance/rfr_performx.pkl')





# future importance
#df_feature_importance = pd.DataFrame(best_randf_model['regressor'].feature_importances_, columns=["coef"], index=X_encode.columns)
#print(f"Shape: {df_feature_importance.shape}")
#df_feature_importance.head()


#fig=plt.figure(figsize=[10,12])
#fig.patch.set_alpha(0.7)
#plt.title(" Répresentation des coefficients",size=18)
#plt.barh(X_encode.columns, best_randf_model['regressor'].feature_importances_,color="#0000FF",edgecolor='blue')






xgb_pipe = Pipeline(
    steps=[("preprocessor", preprocessor), ("regressor", XGBRegressor())]
)
xgb_pipe


# Premier entrainement
xgb_pipe.fit(X_train, y_train)


# get performances in train & test
perform=get_all_performances(value_train=(y_train, xgb_pipe.predict(X_train)),
                     values_test=(y_test, xgb_pipe.predict(X_test)),
                     metrics=METRICS)
perform





# optimisation des hyperparamètres
param_grid_xgb = {
     "regressor__n_estimators" : [100, 200, 300],
    "regressor__max_depth" : [3, 6, 9],
    "regressor__gamma" : [0.01, 0.1],
    "regressor__learning_rate" : [0.001, 0.01, 0.1, 1]
}
GS_xgb = GridSearchCV(xgb_pipe, param_grid_xgb, cv=5, scoring="r2", return_train_score=True)
GS_xgb


# les meilleurs paramètres
GS_xgb.fit(X_train, y_train)


# les meilleurs paramètres
best_params = GS_xgb.best_params_
print(f"Best params: {best_params}")


# entrainement du meilleur modele
best_xgb_model = GS_xgb.best_estimator_
best_xgb_model.fit(X_train,y_train)





# predictions
y_train_predXGB = best_xgb_model.predict(X_train)
y_test_predXGB = best_xgb_model.predict(X_test)

# get performances in train & test
perform=get_all_performances(value_train=(y_train, y_train_predXGB),
                     values_test=(y_test, y_test_predXGB),
                     metrics=METRICS
                    )
perform
joblib.dump(perform, '../ressource/performance/xgb_perform.pkl')


# graphique
sns.set()
fig, axs = plt.subplots(1, 2, figsize=(15, 5))
sns.scatterplot(x = y_test, y = y_test_predXGB, alpha = 0.6, ax = axs[0], color='blue', label='données test')
sns.lineplot(x=y_test, y=y_test, ax = axs[0], color='red', label='Ligne parfaite')
axs[0].set_xlabel(" consommation annuelle réelle ")
axs[0].set_ylabel("consommation annuelle prédites")
axs[0].set_title(" réelle vs prédite (test)")
sns.scatterplot(x = y_train, y = y_train_predXGB, alpha = 0.6, ax = axs[1], color='blue', label='données train')
sns.lineplot(x=y_train, y=y_train, ax = axs[1], color='red', label='Ligne parfaite')
axs[1].set_xlabel(" consommation annuelle réelle ")
axs[1].set_ylabel("consommation annuelle prédites")
axs[1].set_title(" réelle vs prédite (train)")
plt.show()





# future importance
#df_feature_importance = pd.DataFrame(best_xgb_model['regressor'].feature_importances_, columns=["coef"], index=X_encode.columns)
#print(f"Shape: {df_feature_importance.shape}")
#df_feature_importance.head()


#fig=plt.figure(figsize=[10,12])
#fig.patch.set_alpha(0.7)
#plt.title(" Répresentation des coefficients",size=18)
#plt.barh(X_encode.columns, best_xgb_model['regressor'].feature_importances_,color="#0000FF",edgecolor='blue')






from lightgbm import LGBMRegressor # import the LGBMRegressor class from the lightgbm module.

lgbm_pipe = Pipeline(
    steps=[("preprocessor", preprocessor), ("regressor", LGBMRegressor())]
)
lgbm_pipe


# premier entrainement
lgbm_pipe.fit(X_train, y_train)


# get performances in train & test
perform=get_all_performances(value_train=(y_train, lgbm_pipe.predict(X_train)),
                     values_test=(y_test, lgbm_pipe.predict(X_test)),
                     metrics=METRICS
                    )
perform





# optimisation des hyperparamètres
param_grid_lgb = {
    'regressor__num_leaves': [131, 255],
    'regressor__max_depth': [-1, 30],
    'regressor__learning_rate': [0.001, 0.2],
    'regressor__n_estimators': [10, 50],
   # 'regressor__min_split_gain': [0.0, 0.2],
    #'regressor__min_child_samples': [10, 30],
    #'regressor__subsample': [0.8, 0.9, 1.0],
    #'regressor__reg_alpha': [0.0, 0.1, 0.5],
    #'regressor__reg_lambda': [0.001, 0.1],
    #'regressor__objective': ['mse'],
    #'regressor__feature_fraction': 0.75,
    #'regressor__bagging_fraction': 0.75,
    #'regressor__bagging_freq': 5,
}

GS_lgb = GridSearchCV(xgb_pipe, param_grid_lgb, cv=5, scoring="r2", return_train_score=True)
GS_lgb


# les meilleurs paramètres
GS_lgb.fit(X_train, y_train)


# les meilleurs paramètres
best_params = GS_lgb.best_params_
print(f"Best params: {best_params}")


# entrainement du meilleur modele
best_lgb_model = GS_lgb.best_estimator_
best_lgb_model.fit(X_train,y_train)


# entrainement du meilleur modele
best_lgb_model = GS_lgb.best_estimator_
best_lgb_model.fit(X_train,y_train)


perform=get_all_performances(value_train=(y_train, best_lgb_model.predict(X_train)),
                     values_test=(y_test, best_lgb_model.predict(X_test)),
                     metrics=METRICS
                    )
perform



joblib.dump(perform, '../ressource/performance/lgb_perform.pkl')





# future importance
#df_feature_importance = pd.DataFrame(best_lgb_model['regressor'].feature_importances_, columns=["coef"], index=X_encode.columns)
#print(f"Shape: {df_feature_importance.shape}")
#df_feature_importance.head()


#fig=plt.figure(figsize=[10,12])
#fig.patch.set_alpha(0.7)
#plt.title(" Répresentation des coefficients",size=18)
#plt.barh(X_encode.columns, best_lgb_model['regressor'].feature_importances_,color="#0000FF",edgecolor='blue')






# Regression lineaire
score_Lr_Train = GS_lr.score(X_train, y_train)
score_Lr_Test = GS_lr.score(X_test, y_test)

# ElasticNet
score_EN_Train = best_elasticnet_model.score(X_train, y_train)
score_EN_Test = best_elasticnet_model.score(X_test, y_test)

# Random Forest
score_RF_Train = best_randf_model.score(X_train, y_train)
score_RF_Test = best_randf_model.score(X_test, y_test)

# XGBoost
score_XGB_Train = best_xgb_model.score(X_train, y_train)
score_XGB_Test = best_xgb_model.score(X_test, y_test)

# Light GBM
score_LGB_Train = best_lgb_model.score(X_train, y_train)
score_LGB_Test = best_lgb_model.score(X_test, y_test)


models = ['Régression linéaire', 'ElasticNet', 'Random Forest', 'XGBoost', 'Light GBM']
train_scores = [score_Lr_Train, score_EN_Train, score_RF_Train, score_XGB_Train, score_LGB_Train]
test_scores = [score_Lr_Test, score_EN_Test, score_RF_Test, score_XGB_Test, score_LGB_Test]

scores_df = pd.DataFrame({'Modèle': models * 2,
                          'Score': train_scores + test_scores,
                          'R2': ['Entraînement'] * len(models) + ['Test'] * len(models)})

sns.set_palette("viridis")

plt.figure(figsize=(9, 9))
sns.barplot(x='Modèle', y='Score', hue='R2', data=scores_df, ci=None)
plt.xlabel('Modèle')
plt.ylabel('Score (R2)')
plt.title('Scores des Modèles sur Entraînement et Test')
plt.legend(title='R2')

plt.show()





best_lgb_model.fit(X,y)
print (f'Score final - : {best_lgb_model.score(X,y):.7f}')






y_pred = best_lgb_model.predict(X)





comparaison=pd.DataFrame(y_pred,columns=["Prédites"],index=y.index)
comparaison["Réelles"]=y
np.exp(comparaison.head())


plt.figure(figsize=(8, 6))

sns.scatterplot(x=np.exp(y), y=np.exp(y_pred), alpha=0.6)
sns.lineplot(x=np.exp(y), y=np.exp(y), color='skyblue')  # Ligne de référence en rouge
plt.xlabel("prix réelle")
plt.ylabel("prix prédit")
plt.title("Réelle vs Prédite (Train)")

plt.show()


# graphique de comparaison
plt.figure(figsize=(12, 8))
sns.set_palette("husl")
sns.lineplot(data=comparaison[['Prédites', 'Réelles']], linewidth=2)
plt.title("Comparaison entre valeurs réelles et les valeurs prédites", size=18)
plt.xlabel("Échantillons")
plt.ylabel("Valeurs")
plt.legend(labels=['Prédites', 'Réelles'])
plt.grid(True, linestyle='-', alpha=0.6)
plt.show()





joblib.dump(best_lgb_model, '../ressource/modele_final/lgb_model.pkl')
joblib.dump(pipeline, '../ressource/pipeline/pipeline.pkl')
